---
title: |-
  Abstract
pagenum: 1
prev_page:
  url: /intro.html
next_page:
  url: /results.html
suffix: .md
search: resolution data images our fake high samples face faces method accuracy achieved results real sets need detect such approach good annotated unsupervised evaluation set achieves note source code github com cc hpc itwm deepfakedetection deep generative models recently impressive world applications successfully generating diverse complex due improvement digital contents proliferated growing concern spreading distrust image content leading urgent automated ways ai generated despite fact editing algorithms seem produce realistic human upon closer examination exhibit artifacts certain domains often hidden naked eye work present simple called deepfakes based classical frequency domain analysis followed basic classifier compared previous systems fed large amounts

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Abstract</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<blockquote><p><strong>âš  Note:  Source Code:</strong><br>
<a href="https://github.com/cc-hpc-itwm/DeepFakeDetection">https://github.com/cc-hpc-itwm/DeepFakeDetection</a></p>
</blockquote>
<p>Deep generative models have recently achieved impressive results for many real-world applications, successfully
generating high-resolution and diverse samples from complex
data sets. Due to this improvement, fake digital contents have
proliferated growing concern and spreading distrust in image
content, leading to an urgent need for automated ways to detect
these AI-generated fake images.</p>
<p>Despite the fact that many face editing algorithms seem
to produce realistic human faces, upon closer examination,
they do exhibit artifacts in certain domains which are often
hidden to the naked eye. In this work, we present a simple
way to detect such fake face images - so-called DeepFakes.
Our method is based on a classical frequency domain analysis
followed by a basic classifier.</p>
<p>Compared to previous systems,
which need to be fed with large amounts of labeled data,
our approach showed very good results using only a few
annotated training samples and even achieved good accuracies
in fully unsupervised scenarios. For the evaluation on high
resolution face images, we combined several public data sets
of real and fake faces into a new benchmark: Faces-HQ.</p>
<p>Given such high-resolution images, our approach reaches a
perfect classification accuracy of 100% when it is trained on
as little as 20 annotated samples. In a second experiment, in
the evaluation of the medium-resolution images of the CelebA
data set, our method achieves 100% accuracy supervised
and 96% in an unsupervised setting. Finally, evaluating a
low-resolution video sequences of the FaceForensics++ data set,
our method achieves 90% accuracy detecting manipulated videos.</p>

</div>
</div>
</div>
</div>

 


    </main>
    